# WebsiteCrawler
This java project aims to crawl, store hypertext links and traverse them given in a website link. It recursively traverse visit all links store until a user stop the process.  One advantage of this code that It avoid loops by omitting any website that has already been visited; this can be achieved by utilizing digital signature of each website (i.e. Using symmetric key (AES -128)) and make a database preserves uniqueness of inserted a crawled URL content. It also populates extracted textual contents from HTML (impotent data) files and original html files themselves...

Sultan Alzahrani
